{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8386bc36-3e4d-4368-84ae-553330373525",
   "metadata": {},
   "source": [
    "# Scraper\n",
    "\n",
    "This scraping code is built upoin the `scrape.py` code provided\n",
    "\n",
    "All scrapes are in with domain's [robot.txt](https://www.domain.com.au/robots.txt)\n",
    "\n",
    "The scrapping take a long time and is dependent on the date scrape. Because of this a pre-scrapped file is provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcbd68c-cbd6-4a31-98cb-da48ff800923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "\n",
    "BASE_URL = \"https://www.domain.com.au\"\n",
    "\n",
    "DIR_RAW = \"../data/raw/\"\n",
    "\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0 (X11; CrOS x86_64 12871.102.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.141 Safari/537.36\"}\n",
    "\n",
    "PERCENTAGES = range(1, 101, 5)\n",
    "\n",
    "REQUEST_WAIT_TIME = 0.2\n",
    "\n",
    "# get list of VIC postcodes\n",
    "df_postcodes = pd.read_csv(f\"{DIR_RAW}postcodes.csv\")\n",
    "df_postcodes = df_postcodes[df_postcodes[\"state\"] == \"VIC\"]\n",
    "postcodes = set(df_postcodes[\"postcode\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78431df0-e2c7-4007-b6ba-4f9d09ea7221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_display_percentages(xs):\n",
    "    display_percentages = [round(len(xs) * (percentage/100)) for percentage in PERCENTAGES]\n",
    "    display_percentages[0] = 1\n",
    "    display_percentages[-1] = len(xs)\n",
    "    return display_percentages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb8c947-ca8a-4c07-95e2-cd05a1fffd94",
   "metadata": {},
   "source": [
    "## Collect property URLs by postcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc6e845-6b7e-4d17-9ba4-b5f4fb7145c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_urls = set()\n",
    "\n",
    "postcode_num = 0\n",
    "display_percentage = get_display_percentages(postcodes)\n",
    "\n",
    "for postcode in postcodes:\n",
    "\n",
    "    page_num = 1\n",
    "    while True:\n",
    "        \n",
    "        page_url = f\"{BASE_URL}/rent/?postcode={postcode}&page={page_num}\"\n",
    "        content = BeautifulSoup(requests.get(page_url, headers=HEADERS).text, \"html.parser\")\n",
    "        \n",
    "        # collect all candidate property links on page\n",
    "        links = content.find(\"ul\", {\"data-testid\": \"results\"})\n",
    "        if not links:\n",
    "            break\n",
    "            \n",
    "        links = links.findAll(\"a\", href=re.compile(f\"{BASE_URL}/*\"))\n",
    "        if not links:\n",
    "            break\n",
    "        \n",
    "        for link in links:\n",
    "            if \"address\" in link[\"class\"]:\n",
    "                property_urls.add(link[\"href\"])\n",
    "        \n",
    "        page_num += 1\n",
    "        \n",
    "        # wait a little time in-between each request to prevent DDOS attack\n",
    "        sleep(REQUEST_WAIT_TIME)\n",
    "    \n",
    "    postcode_num += 1\n",
    "    if postcode_num in display_percentage:\n",
    "        print(f\"{round(postcode_num / len(postcodes) * 100)}% of VIC postcode URLs scraped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016c97b0-4f5c-4948-88a7-8ddea4e2cf3b",
   "metadata": {},
   "source": [
    "## Scrape each URL collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fdebde-717c-4751-a69d-3a97805f8b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "property_url_num = 0\n",
    "display_percentage = get_display_percentages(property_urls)\n",
    "\n",
    "for property_url in property_urls:\n",
    "    \n",
    "    current_scrape = {\"url\": property_url}\n",
    "    \n",
    "    content = BeautifulSoup(requests.get(property_url, headers=HEADERS).text, \"html.parser\")\n",
    "\n",
    "    if not content:\n",
    "        pass\n",
    "\n",
    "    content_price = content.find(\"div\", {\"data-testid\": \"listing-details__summary-title\"})\n",
    "\n",
    "    content_address = content.find(\"h1\", {\"class\": \"css-164r41r\"})\n",
    "\n",
    "    content_features = content.find(\"div\", {\"data-testid\": \"property-features\"})\n",
    "    if content_features:\n",
    "        content_features = content_features.findAll(\"span\", {\"data-testid\": \"property-features-text-container\"})\n",
    "\n",
    "    content_property_type = content.find(\"div\", {\"data-testid\": \"listing-summary-property-type\"})\n",
    "\n",
    "    content_agent = content.find(\"a\", {\"data-testid\": \"listing-details__agent-details-agent-company-name\"})\n",
    "\n",
    "    content_summary = content.find(\"div\", {\"data-testid\": \"strip-content-list\"})\n",
    "    if content_summary:\n",
    "        content_summary = content_summary.findAll(\"li\")\n",
    "\n",
    "    content_domain_says = content.find(\"p\", {\"data-testid\": \"listing-details__domain-says-text\"})\n",
    "\n",
    "    content_neighbourhood_insights = content.find(\"section\", {\"data-testid\": \"neighbourhood-insights\"})\n",
    "    if content_neighbourhood_insights:\n",
    "        content_age = content.findAll(\"tr\", {\"data-testid\": \"neighbourhood-insights__age-brackets-row\"})\n",
    "        content_long_term_residents = content.find(\"div\", {\"data-testid\": \"single-value-doughnut-graph\"})\n",
    "        content_type = content.findAll(\"div\", {\"class\": \"css-14hea9r\"})\n",
    "    else:\n",
    "        content_age = content_long_term_residents = content_type = None\n",
    "\n",
    "    content_stats = content.find(\"div\", {\"data-testid\": \"listing-details__suburb-insights\"})\n",
    "    if content_stats:\n",
    "        content_values = content_stats.findAll(\"div\", {\"class\": \"css-35ezg3\"})\n",
    "\n",
    "        content_occupancy = content_stats.find(\"div\", {\"data-testid\": \"suburb-insights__occupancy\"})\n",
    "        content_household = content_stats.find(\"div\", {\"data-testid\": \"suburb-insights__household\"})\n",
    "    else:\n",
    "        content_values = content_occupancy = content_household = None\n",
    "\n",
    "    content_coordinates = content.find(\"a\", {\"target\": \"_blank\", \"rel\": \"noopener noreferer\"})\n",
    "\n",
    "    if content_price:\n",
    "        current_scrape[\"price\"] = content_price.getText()\n",
    "\n",
    "    if content_address:\n",
    "        current_scrape[\"address\"] = content_address.getText()\n",
    "\n",
    "    if content_features and len(content_features) >= 1:\n",
    "        current_scrape[\"num_beds\"] = content_features[0].getText()\n",
    "\n",
    "    if content_features and len(content_features) >= 2:\n",
    "        current_scrape[\"num_bath\"] = content_features[1].getText()\n",
    "\n",
    "    if content_features and len(content_features) >= 3:\n",
    "        current_scrape[\"num_car\"] = content_features[2].getText()\n",
    "\n",
    "    if content_property_type:\n",
    "        current_scrape[\"property_type\"] = content_property_type.getText()\n",
    "\n",
    "    if content_agent:\n",
    "        current_scrape[\"agent\"] = content_agent.getText()\n",
    "\n",
    "    if content_summary:\n",
    "        for entry in content_summary:\n",
    "            bond_found = re.findall(r\"([bB]ond \\$[0-9,\\.]+)\",  entry.getText())\n",
    "            internal_area_found = re.findall(r\"([iI]nternal area .+)\",  entry.getText())\n",
    "            land_area_found = re.findall(r\"([lL]and area .+)\",  entry.getText())\n",
    "\n",
    "            if bond_found:\n",
    "                current_scrape[\"bond\"] = bond_found[0]\n",
    "\n",
    "            if internal_area_found:\n",
    "                current_scrape[\"internal_area\"] = internal_area_found[0]\n",
    "\n",
    "            if land_area_found:\n",
    "                current_scrape[\"land_area\"] = land_area_found[0]\n",
    "\n",
    "    if content_domain_says:\n",
    "        current_scrape[\"domain_says\"] = content_domain_says.getText()\n",
    "\n",
    "    if content_age and len(content_age) >= 4:\n",
    "        content_under_20 = content_age[0].find(\"div\", {\"data-testid\": \"bar-value\"})\n",
    "        content_20_to_39 = content_age[1].find(\"div\", {\"data-testid\": \"bar-value\"})\n",
    "        content_40_to_59 = content_age[2].find(\"div\", {\"data-testid\": \"bar-value\"})\n",
    "        content_above_60 = content_age[3].find(\"div\", {\"data-testid\": \"bar-value\"})\n",
    "\n",
    "        if content_under_20:\n",
    "            current_scrape[\"neighbourhood_under_20\"] = content_under_20.getText()\n",
    "\n",
    "        if content_20_to_39:\n",
    "            current_scrape[\"neighbourhood_20_to_39\"] = content_20_to_39.getText()\n",
    "\n",
    "        if content_40_to_59:\n",
    "            current_scrape[\"neighbourhood_40_to_59\"] = content_40_to_59.getText()\n",
    "\n",
    "        if content_above_60:\n",
    "            current_scrape[\"neighbourhood_above_60\"] = content_above_60.getText()\n",
    "\n",
    "    if content_long_term_residents:\n",
    "        current_scrape[\"neighbourhood_long_term_residents\"] = content_long_term_residents.getText()\n",
    "\n",
    "    if content_type and len(content_type) >= 4:\n",
    "        content_owners = content_type[0].find(\"span\", {\"data-testid\": \"left-value\"})\n",
    "        content_renter = content_type[0].find(\"span\", {\"data-testid\": \"right-value\"})\n",
    "        content_family = content_type[1].find(\"span\", {\"data-testid\": \"left-value\"})\n",
    "        content_single = content_type[1].find(\"span\", {\"data-testid\": \"right-value\"})\n",
    "\n",
    "        if content_owners:\n",
    "            current_scrape[\"neighbourhood_owners\"] = content_owners.getText()\n",
    "\n",
    "        if content_renter:\n",
    "            current_scrape[\"neighbourhood_renter\"] = content_renter.getText()\n",
    "\n",
    "        if content_family:\n",
    "            current_scrape[\"neighbourhood_family\"] = content_family.getText()\n",
    "\n",
    "        if content_single:\n",
    "            current_scrape[\"neighbourhood_single\"] = content_single.getText()\n",
    "\n",
    "    if content_values and len(content_values) >= 6:\n",
    "        current_scrape[\"performance_median_price\"] = content_values[0].getText()\n",
    "        current_scrape[\"performance_auction_clearance\"] = content_values[1].getText()\n",
    "        current_scrape[\"performance_sold_this_year\"] = content_values[2].getText()\n",
    "        current_scrape[\"performance_avg_days_on_market\"] = content_values[3].getText()\n",
    "\n",
    "        current_scrape[\"demographic_population\"] = content_values[4].getText()\n",
    "        current_scrape[\"demographic_average_age\"] = content_values[5].getText()\n",
    "\n",
    "    if content_occupancy:\n",
    "        content_owners = content_occupancy.find(\"span\", {\"data-testid\": \"left-value\"})\n",
    "        content_renter = content_occupancy.find(\"span\", {\"data-testid\": \"right-value\"})\n",
    "\n",
    "        if content_owners:\n",
    "            current_scrape[\"demographic_owner\"] = content_owners.getText()\n",
    "\n",
    "        if content_renter:\n",
    "            current_scrape[\"demographic_renter\"] = content_renter.getText()\n",
    "\n",
    "    if content_household:\n",
    "        content_family = content_household.find(\"span\", {\"data-testid\": \"left-value\"})\n",
    "        content_single = content_household.find(\"span\", {\"data-testid\": \"right-value\"})\n",
    "\n",
    "        if content_family:\n",
    "            current_scrape[\"demographic_family\"] = content_family.getText()\n",
    "\n",
    "        if content_single:\n",
    "            current_scrape[\"demographic_single\"] = content_single.getText()\n",
    "\n",
    "    if content_coordinates:\n",
    "        coordinates = re.findall(r\"destination=([-\\s,\\d\\.]+)\", content_coordinates.attrs[\"href\"])\n",
    "        if coordinates:\n",
    "            coordinates = coordinates[0].split(\",\")\n",
    "            current_scrape[\"latitude\"] = coordinates[0]\n",
    "            current_scrape[\"longitude\"] = coordinates[1]           \n",
    "    \n",
    "    data.append(current_scrape)\n",
    "    \n",
    "    # wait a little time in-between each request to prevent DDOS attack\n",
    "    sleep(REQUEST_WAIT_TIME)\n",
    "    \n",
    "    property_url_num += 1\n",
    "    if property_url_num in display_percentage:\n",
    "        print(f\"{round(property_url_num / len(property_urls) * 100)}% of property URLs scraped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c371240f-50bd-458d-99a8-348dbd64eb19",
   "metadata": {},
   "source": [
    "## Save scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d48ae46-3525-4e58-a39a-38c0c74c43e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scrape = pd.json_normalize(data)\n",
    "display(df_scrape.head(10))\n",
    "\n",
    "df_scrape.to_csv(f\"{DIR_RAW}/scraped_properties.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
