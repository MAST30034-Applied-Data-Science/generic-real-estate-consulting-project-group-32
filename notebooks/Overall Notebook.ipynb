{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0125b53-e7f2-41db-a4e0-2a68dd9ce47f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db02d6fd-7e1c-495c-885b-6a78d82e6026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "repo_path = os.path.abspath('../')\n",
    "sys.path.append(repo_path)\n",
    "import scripts.addSA2 as addSA2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import geoplot.crs as gcrs\n",
    "import geopandas as gpd\n",
    "import geoplot as gplt\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b0991c-b92e-476f-a320-2693e95d2f11",
   "metadata": {},
   "source": [
    "## Data Download\n",
    "\n",
    "The first thing we need to do is download the datasources needed for our analysis.\n",
    "\n",
    "This involves:\n",
    "-> median income by SA2 level\n",
    "-> population by SA2 level\n",
    "-> SA2 Shape files\n",
    "-> school location data\n",
    "-> postcode/sa2 data\n",
    "(see data_download.py in the script folder for details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d36c0b0-f38e-4cd9-9e0e-1c50bd963da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../scripts/data_download.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53895a17-0db7-48b0-ad72-4dc19dcf74c0",
   "metadata": {},
   "source": [
    "## Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2127d91d-2527-447f-9f4e-240e3aad1a36",
   "metadata": {},
   "source": [
    "For this project we decided to scrape rental data from domain.com.au.\n",
    "This website has a huge number of listings, and by searching by postcode we collected a large number of metrics from each listed property.\n",
    "\n",
    "This process is done in scrape.ipynb, and the results are saved in the raw data folder. as scraped_properties.csv as seen below.\n",
    "(This will not be run in this notebook as it takes an extremely long time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b53f274-7d11-45c6-80aa-ba941d03746a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped = pd.read_csv(f\"../data/raw/scraped_properties.csv\")\n",
    "display(scraped.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f44445-54e7-41e6-a71c-a9503ff71eab",
   "metadata": {},
   "source": [
    "## API Data\n",
    "\n",
    "Now we get a bunch of distance data for various properties that we can merge into our other data\n",
    "\n",
    "This is done with the school_proximities.ipynb notebook. But is quite an involved process, so that data is saved inside the git repository instead of being run here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b51427-74b1-499b-8fec-d2d4141f2417",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2a545b-c28d-4a98-aee9-e0aff70578fb",
   "metadata": {},
   "source": [
    "While this gives us a lot of raw data, it needs to be put into a useable format first. This is done in pre_processing.py. By using a variety of regex rules to extract the relevant numbers from the data. We also need to remove a specific NSW town that was caught in the scrape for some reason. We also remove carspaces as they are not relevant to the problems.\n",
    "\n",
    "From there we merge with the API distance data that has been gathered.\n",
    "\n",
    "Now we can remove outliers. This is done mainly by plotting a linear regression model using:\n",
    "-> number of beds\n",
    "-> number of baths\n",
    "-> number of parking spaces\n",
    "-> distance to a school\n",
    "-> distance to a park\n",
    "-> distance to a shop\n",
    "-> bond\n",
    "and use this to predict rent price.\n",
    "\n",
    "From this we reject values with a high cooks distance.\n",
    "(See pre_processing.ipynb for proper details, as the .py file is purely for this notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3048120-4941-4fe4-bc66-9d61616f7ce1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run ../scripts/pre_processing.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13755519-1d92-4843-82cf-63221fd62e78",
   "metadata": {},
   "source": [
    "Now our data looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2757c345-3a47-4ad1-8708-c1ba5d9c1aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed = pd.read_csv(f\"../data/curated/pre_processed_data.csv\")\n",
    "display(pre_processed.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8311aa86-92be-4d0c-8e4a-d6e1087d3c7d",
   "metadata": {},
   "source": [
    "We can also add in the SA2 zone and corresponding geometry for each of these listings. This allows us to visualise the data in various ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94575fe-85e0-4647-be0b-4d4226657867",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa2_grouped = addSA2.addSA2(pre_processed, use_postcode=False)\n",
    "\n",
    "\n",
    "sa2_grouped = sa2_grouped.groupby(\"SA2\").mean().reset_index()\n",
    "\n",
    "shape = gpd.read_file('../data/raw/ShapeFile/SA2_2021_AUST_GDA2020.shp')\n",
    "shape = shape.loc[shape.STE_NAME21 == \"Victoria\"]\n",
    "shape = shape.loc[shape.geometry != None]\n",
    "shape[\"SA2_CODE21\"] = pd.to_numeric(shape[\"SA2_CODE21\"], errors='ignore')\n",
    "sa2_grouped = gpd.GeoDataFrame(sa2_grouped.join(shape.set_index(\"SA2_CODE21\")[\"geometry\"], on=\"SA2\"))\n",
    "sa2_grouped = sa2_grouped[sa2_grouped[\"geometry\"] != None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cee9f4-9c53-4bc6-9231-57545acfea84",
   "metadata": {},
   "source": [
    "If you want to see a plot of any feature, simply type the feature into the \"FEATURE HERE\" section below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88b8212-9a6f-4d67-9e18-562ff3552d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the lines for the visualisation\n",
    "ax = gplt.polyplot(shape, figsize=(100, 50))\n",
    "# create a heatmap based on a particular feature\n",
    "gplt.choropleth(\n",
    "  sa2_grouped,\n",
    "  hue=\"count\",\n",
    "  edgecolor=\"black\",\n",
    "  linewidth=0.1,\n",
    "  cmap=\"Greens\",\n",
    "  legend=True,\n",
    "  ax=ax\n",
    ")\n",
    "\n",
    "plt.savefig(\"counts.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e797d17a-0173-47b8-b035-3618f481e3b1",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dcf02b-0e8f-4a99-bacb-37d2dc9ff7f5",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669afba7-c65d-4086-93e7-8911f48799cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "DIR_CUR = \"../data/curated/\"\n",
    "DIR_PLT = \"../plots/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c0d222-c774-4dd3-8cd1-186edb7b63cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in suburb level version of data\n",
    "df = pd.read_csv(f\"{DIR_CUR}suburb_data.csv\")\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172acd1a-7b3a-4962-918b-7ce22b0cd0a3",
   "metadata": {},
   "source": [
    "## Most important data distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8549e03a-e7b6-4487-85b5-a53495d1f0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution(x, bins, x_lab):\n",
    "    plt.hist(x, bins=bins, density=True)\n",
    "    plt.title(f\"{x_lab} Distribution\", size=20)\n",
    "    plt.xlabel(x_lab, size=16)\n",
    "    plt.ylabel(\"Frequency\", size=16)\n",
    "    plt.show()\n",
    "    \n",
    "distribution(df[\"weekly_rent\"], 30, \"Weekly Rent (AUS)\", )\n",
    "#distribution(df[\"bond\"], 30, \"Bond (AUS)\")\n",
    "distribution(df[\"school_distance\"], 30, \"School Distance (m)\")\n",
    "distribution(df[\"park_distance\"], 30, \"Park Distance (m)\")\n",
    "distribution(df[\"shop_distance\"], 30, \"Shop Distance (m)\")\n",
    "distribution(df[\"train_distance\"], 30, \"Train Distance (m)\")\n",
    "distribution(df[\"stop_distance\"], 30, \"Stop Distance (m)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbef879-65ca-4f24-a776-e3cb8fb92ea0",
   "metadata": {},
   "source": [
    "## VS plots\n",
    "(uncomment the variable you want to see)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b719a7ba-de7f-44fd-825a-1d06e3e4b179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vs(x, y, x_lab, y_lab, x_trans=lambda x: x, y_trans=lambda x: x):\n",
    "    plt.scatter(x_trans(x), y_trans(y))\n",
    "    plt.title(f\"{y_lab} vs {x_lab}\", size=20)\n",
    "    plt.xlabel(x_lab, size=16)\n",
    "    plt.ylabel(y_lab, size=16)\n",
    "    plt.show()\n",
    "\n",
    "vs(df[\"school_distance\"], df[\"weekly_rent\"], \"School Distance (m)\", \"Weekly Rent (AUS)\")\n",
    "#vs(df[\"park_distance\"],   df[\"weekly_rent\"], \"Park Distance (m)\",   \"Weekly Rent (AUS)\")\n",
    "#vs(df[\"shop_distance\"],   df[\"weekly_rent\"], \"Shop Distance (m)\",   \"Weekly Rent (AUS)\")\n",
    "#vs(df[\"train_distance\"],  df[\"weekly_rent\"], \"Train Distance (m)\",  \"Weekly Rent (AUS)\")\n",
    "#vs(df[\"stop_distance\"],   df[\"weekly_rent\"], \"Stop Distance (m)\",   \"Weekly Rent (AUS)\")\n",
    "\n",
    "#vs(df[\"population\"], df[\"weekly_rent\"], \"Population\", \"Weekly Rent (AUS)\")\n",
    "\n",
    "#vs(df[\"count\"], df[\"weekly_rent\"], \"_\", \"Weekly Rent (AUS)\")\n",
    "\n",
    "#vs(df[\"performance_avg_days_on_market\"], df[\"weekly_rent\"], \"_\", \"Weekly Rent (AUS)\")\n",
    "#vs(df[\"median_weekly_income\"], df[\"weekly_rent\"], \"median weekly income\", \"Weekly Rent (AUS)\")\n",
    "#vs(df[\"performance_median_price\"], df[\"weekly_rent\"], \"Median Price\", \"Weekly Rent (AUS)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56c351f-7a8a-46c3-98bf-79a4a8ba188f",
   "metadata": {},
   "source": [
    "Cross validation used in full model, however not used here as it takes longer to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84f6b2e-ea1b-450c-bc01-4fdb254e3051",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = \"weekly_rent\"\n",
    "predictors = [\"median_weekly_income\", \"performance_median_price\"] \n",
    "\n",
    "df_na_out = df.dropna(subset=predictors)\n",
    "\n",
    "trans = ColumnTransformer(transformers=[(\"scale\", StandardScaler(), predictors)],\n",
    "                          remainder=\"passthrough\") \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_na_out[predictors],\n",
    "                                                    df_na_out[response],\n",
    "                                                    test_size=0.20,\n",
    "                                                    random_state=30027)\n",
    "\n",
    "x_train_trans = trans.fit_transform(x_train)\n",
    "x_test_trans = trans.fit_transform(x_test)\n",
    "\n",
    "model = MLPRegressor(random_state=30027, max_iter=1000000, n_iter_no_change=15).fit(x_train_trans, y_train)\n",
    "model.score(x_test_trans, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ccefc1-6f0d-472b-b7a4-c8d38f995389",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "model_2 = LinearRegression().fit(x_train_trans, y_train)\n",
    "model_2.score(x_test_trans, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5e00d0-1867-4e8f-bfe8-2d5a41fa21d2",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a40e74-2fe3-48c5-b7e9-b966bab0c1a0",
   "metadata": {},
   "source": [
    "For this question we need historical data instead of current, data. This has been scraped from domain.com.au, and is pre-processed seperately. (See predict_future_preprocess.ipynb for details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485ff32b-b555-4b9b-b85c-f8814c362d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../scripts/predict_future_preprocessing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fc416a-41ba-44d8-8281-5d9d37d8d559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read in the dataframe for predictions\n",
    "df = pd.read_csv(f\"../data/curated/future_prediction_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2179da-b9f8-41a9-8011-d97d4e3974bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdc999d-fecf-4088-9c8e-f498a4f87b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the linear model, exclude 0 clearance rate and no new building locations.\n",
    "df = df[df[\"clearance\"] != 0]\n",
    "df = df[df[\"new_dwellings_2019\"] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ea3a7d-32f4-4aa0-a11c-e041bd709842",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"2019_n_sold\", \"suburb_population\", \"new_dwellings_2019\", \"non_residential_value_2019\"]]\n",
    "y = df[\"3_year_growth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41494d38-be0b-404f-8bfc-88490a9dba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a linear model to the data\n",
    "reg = LinearRegression().fit(X,y)\n",
    "reg.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b390bd-d681-4464-90f2-7eb86c63d56e",
   "metadata": {},
   "source": [
    "Clearly, using a linear regression on historical data is not a valid method, so we will have to try another method to predict future value.\n",
    "Instead we will have to take a non-statistical approach, and use the suburb metrics that we have access to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a139ea3-c6b8-4232-83d1-7d4f7594c9d8",
   "metadata": {},
   "source": [
    "## Predictor Metrics:\n",
    "\n",
    "Historical 3-year-growth: While a regression to the mean is fairly likely in many cases, a suburb having a high growth rate in previous years should still indicate that that is more likely to continue.\n",
    "\n",
    "Current growth rate: Extrapolating the 2022 growth rate to a 3 year prediction is unlikely to be accurate, but it is once again a decent indicator.\n",
    "\n",
    "New dwellings / population: If there is a high number of new dwellings relative to the population, then in theory the increased supply will lead to decreased house value.\n",
    "\n",
    "non residential value: The theory behind using this metric, is that non-residential housing indicates an increase in local business. This should in theory increase the value of the area. This may be incorrect, as it might indicate a non-residential area, but not sure.\n",
    "\n",
    "Clearance: A high clearance rate should indicate a high demand in the area, so in theory an increase in future prices.\n",
    "\n",
    "Average days on market: A low number of days on the market, should indicate (like clearance), a high demand for houses in the area.\n",
    "\n",
    "sold / population: If there are a high number of sales relative to the population it indicates market interest.\n",
    "\n",
    "Unfortunately due to a lack of historical data for many areas, and many of these metrics, we will have to decide aribtrarily on the importance of each feature. I will then create a ranking of each feature and use this as the input for the algorithm.\n",
    "\n",
    "https://propertyupdate.com.au/property-investment-melbourne/#is-it-the-right-time-to-get-into-the-melbourne-property-market\n",
    "\n",
    "https://www.trilogyfunding.com.au/blog/7-key-market-indicators-every-property-investor-should-understand-april-2015/\n",
    "\n",
    "\n",
    "https://www.mmj.com.au/resources/blog/5-key-market-indicators-every-property-investor-should-know/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfdb737-ae78-4ba0-b57a-8d0ba97f035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"../data/curated/future_prediction_data.csv\")\n",
    "\n",
    "# Get rankings for each feature\n",
    "predict_df = pd.DataFrame()\n",
    "predict_df[\"suburb\"] = df[\"suburb\"]\n",
    "predict_df[\"avg_days_on_market\"] = df[\"avg_days_on_market\"].rank(ascending = False) # low is better\n",
    "predict_df[\"3_year_growth\"] = df[\"3_year_growth\"].rank(ascending = True) # high is better\n",
    "predict_df[\"2022_growth\"] = df[\"2022_growth\"].rank(ascending = True) # high is better\n",
    "predict_df[\"sold/pop\"] = (df[\"2022_n_sold\"]/df[\"suburb_population\"]).rank(ascending = True).fillna(0) # high is better\n",
    "predict_df[\"dwellings/pop\"] = (df[\"new_dwellings_2021\"]/df[\"suburb_population\"]).rank(ascending = False).fillna(0) # low is better\n",
    "predict_df[\"non_residential_value\"] = df[\"non_residential_value_2021\"].rank(ascending = True) # higher is better\n",
    "predict_df[\"clearance\"] = df[\"clearance\"].rank(ascending = True) # higher is better\n",
    "predict_df[\"sum\"] = predict_df.sum(axis=1)\n",
    "predict_df[\"SA2\"] = df[\"SA2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4979b361-3273-425b-aab3-b1e82e869d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df = predict_df.sort_values(by=\"sum\", ascending=False)\n",
    "predict_df.to_csv(f\"../data/curated/prediction_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fd1c92-c981-4cbc-82a0-936a7143f022",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(predict_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187bb0ff-5c3b-4b2c-b1c5-4b1430430b3f",
   "metadata": {},
   "source": [
    "We can then see the ranking of suburbs. Flinders, Blairgowrie, tootgarook, mccrae, and mornington take the top spots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0015769-c17c-47bd-b5fd-e78d0c61cc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = gpd.read_file('../data/raw/ShapeFile/SA2_2021_AUST_GDA2020.shp')\n",
    "shape = shape.loc[shape.STE_NAME21 == \"Victoria\"]\n",
    "shape = shape.loc[shape.geometry != None]\n",
    "shape[\"SA2_CODE21\"] = pd.to_numeric(shape[\"SA2_CODE21\"], errors='ignore')\n",
    "plot_df = predict_df.join(shape[[\"SA2_CODE21\", \"geometry\"]].set_index(\"SA2_CODE21\"), on=\"SA2\")\n",
    "plot_df = plot_df[plot_df[\"geometry\"] != None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122dab92-2986-4bfb-a446-b951a8fe9edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "import geoplot.crs as gcrs\n",
    "\n",
    "\n",
    "ax = gplt.polyplot(shape, figsize=(100, 50))#, projection=gcrs.AlbersEqualArea())\n",
    "\n",
    "gplt.choropleth(\n",
    "  gpd.GeoDataFrame(plot_df),\n",
    "  hue=\"sum\",\n",
    "  edgecolor=\"black\",\n",
    "  linewidth=0.1,\n",
    "  cmap=\"Greens\",\n",
    "  legend=True,\n",
    "  ax=ax\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf9f153-4b6f-4739-aa3c-8a543a89f0af",
   "metadata": {},
   "source": [
    "This graphic shows the results per SA2 zone, but because they don't line up with the suburbs very well, so we get a lot of missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d9d229-11b9-461b-abdc-6e2e39e2204b",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f33312-028e-4353-bb47-967ae18c5290",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"../data/curated/suburb_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1ec1fe-4b92-4456-a46b-47c69bfecd28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
